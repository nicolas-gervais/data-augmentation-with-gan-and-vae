{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='red'>_Accidents</font> in Montreal: Data Cleaning_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- See the documentation [HERE](https://saaq.gouv.qc.ca/donnees-ouvertes/rapports-accident/rapports-accident-documentation.pdf)\n",
    "- Get the data [HERE (http://donnees.ville.montreal.qc.ca/dataset/collisions-routieres)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Procedure\n",
    "- Deleting Useless columns (see documentation)\n",
    "- Make dummy variables for categorical/discrete variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import os \n",
    "os.chdir('c:/users/nicolas/documents/data/accidents-mtl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading data\n",
    "df = pd.read_csv('accidents_2012_2018.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resetting index\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>JR_SEMN_ACCDN</th>\n",
       "      <th>DT_ACCDN</th>\n",
       "      <th>CD_MUNCP</th>\n",
       "      <th>NO_CIVIQ_ACCDN</th>\n",
       "      <th>SFX_NO_CIVQ_ACCDN</th>\n",
       "      <th>BORNE_KM_ACCDN</th>\n",
       "      <th>RUE_ACCDN</th>\n",
       "      <th>TP_REPRR_ACCDN</th>\n",
       "      <th>ACCDN_PRES_DE</th>\n",
       "      <th>NB_METRE_DIST_ACCD</th>\n",
       "      <th>...</th>\n",
       "      <th>NB_VICTIMES_VELO</th>\n",
       "      <th>VITESSE_AUTOR</th>\n",
       "      <th>LOC_X</th>\n",
       "      <th>LOC_Y</th>\n",
       "      <th>LOC_COTE_Q</th>\n",
       "      <th>LOC_COTE_P</th>\n",
       "      <th>LOC_DETACHEE</th>\n",
       "      <th>LOC_IMPRECISION</th>\n",
       "      <th>LOC_LONG</th>\n",
       "      <th>LOC_LAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>ME</td>\n",
       "      <td>2012/02/01</td>\n",
       "      <td>66102.0</td>\n",
       "      <td>3501.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ST CHARLES</td>\n",
       "      <td>2.0</td>\n",
       "      <td>STAT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>276517.37950</td>\n",
       "      <td>5.035127e+06</td>\n",
       "      <td>A</td>\n",
       "      <td>3</td>\n",
       "      <td>O</td>\n",
       "      <td>N</td>\n",
       "      <td>-73.861616</td>\n",
       "      <td>45.455505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>SA</td>\n",
       "      <td>2012/06/02</td>\n",
       "      <td>66023.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COTE VERTU ET AUT 40</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>287913.26000</td>\n",
       "      <td>5.038666e+06</td>\n",
       "      <td>A</td>\n",
       "      <td>3</td>\n",
       "      <td>N</td>\n",
       "      <td>O</td>\n",
       "      <td>-73.716033</td>\n",
       "      <td>45.487715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>JE</td>\n",
       "      <td>2012/06/28</td>\n",
       "      <td>66023.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COTE VERTU</td>\n",
       "      <td>1.0</td>\n",
       "      <td>DECARIE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>290518.82501</td>\n",
       "      <td>5.041617e+06</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>-73.682786</td>\n",
       "      <td>45.514324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>ME</td>\n",
       "      <td>2012/07/11</td>\n",
       "      <td>66023.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ST MATHIEU</td>\n",
       "      <td>1.0</td>\n",
       "      <td>RENE LEVESQUE</td>\n",
       "      <td>50.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>298822.88600</td>\n",
       "      <td>5.039146e+06</td>\n",
       "      <td>A</td>\n",
       "      <td>3</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>-73.576472</td>\n",
       "      <td>45.492212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>LU</td>\n",
       "      <td>2012/01/02</td>\n",
       "      <td>66023.0</td>\n",
       "      <td>4849.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ST JEAN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>277433.35738</td>\n",
       "      <td>5.038881e+06</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>O</td>\n",
       "      <td>N</td>\n",
       "      <td>-73.850114</td>\n",
       "      <td>45.489319</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 67 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  JR_SEMN_ACCDN    DT_ACCDN  CD_MUNCP  NO_CIVIQ_ACCDN SFX_NO_CIVQ_ACCDN  \\\n",
       "0            ME  2012/02/01   66102.0          3501.0               NaN   \n",
       "1            SA  2012/06/02   66023.0             NaN               NaN   \n",
       "2            JE  2012/06/28   66023.0             NaN               NaN   \n",
       "3            ME  2012/07/11   66023.0             NaN               NaN   \n",
       "4            LU  2012/01/02   66023.0          4849.0               NaN   \n",
       "\n",
       "   BORNE_KM_ACCDN   RUE_ACCDN  TP_REPRR_ACCDN         ACCDN_PRES_DE  \\\n",
       "0             NaN  ST CHARLES             2.0                  STAT   \n",
       "1             NaN         NaN             NaN  COTE VERTU ET AUT 40   \n",
       "2             NaN  COTE VERTU             1.0               DECARIE   \n",
       "3             NaN  ST MATHIEU             1.0         RENE LEVESQUE   \n",
       "4             NaN     ST JEAN             NaN                   NaN   \n",
       "\n",
       "   NB_METRE_DIST_ACCD  ...  NB_VICTIMES_VELO  VITESSE_AUTOR         LOC_X  \\\n",
       "0                 NaN  ...                 0            NaN  276517.37950   \n",
       "1                 NaN  ...                 0            NaN  287913.26000   \n",
       "2                 NaN  ...                 0           50.0  290518.82501   \n",
       "3                50.0  ...                 0           50.0  298822.88600   \n",
       "4                 NaN  ...                 0            NaN  277433.35738   \n",
       "\n",
       "          LOC_Y  LOC_COTE_Q  LOC_COTE_P  LOC_DETACHEE  LOC_IMPRECISION  \\\n",
       "0  5.035127e+06           A           3             O                N   \n",
       "1  5.038666e+06           A           3             N                O   \n",
       "2  5.041617e+06           A           1             N                N   \n",
       "3  5.039146e+06           A           3             N                N   \n",
       "4  5.038881e+06           A           1             O                N   \n",
       "\n",
       "    LOC_LONG    LOC_LAT  \n",
       "0 -73.861616  45.455505  \n",
       "1 -73.716033  45.487715  \n",
       "2 -73.682786  45.514324  \n",
       "3 -73.576472  45.492212  \n",
       "4 -73.850114  45.489319  \n",
       "\n",
       "[5 rows x 67 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# head\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deleting Useless Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 171,271 rows and 67 columns.\n"
     ]
    }
   ],
   "source": [
    "rows, columns = df.shape\n",
    "print(f'We have {rows:,} rows and {columns} columns.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deleting columns upon inspection of documentation\n",
    "df.drop(['NO_CIVIQ_ACCDN', 'RUE_ACCDN', 'ACCDN_PRES_DE', 'CD_PNT_CDRNL_ROUTE', \n",
    "         'BORNE_KM_ACCDN', 'NB_METRE_DIST_ACCD', 'CD_PNT_CDRNL_REPRR', \n",
    "         'CD_SIT_PRTCE_ACCDN', 'nb_taxi', 'nb_urgence', 'nb_motoneige', 'nb_VHR', \n",
    "         'nb_autres_types', 'nb_veh_non_precise', 'CD_MUNCP', 'CD_ASPCT_ROUTE',\n",
    "         'REG_ADM', 'MRC', 'LOC_DETACHEE', 'LOC_IMPRECISION', 'LOC_COTE_Q', \n",
    "         'LOC_COTE_P'], \n",
    "         axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 171,271 rows and 47 columns.\n"
     ]
    }
   ],
   "source": [
    "rows, columns = df.shape\n",
    "print(f'We have {rows:,} rows and {columns} columns.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Missing Values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>CD_CONFG_ROUTE</td>\n",
       "      <td>18738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>CD_LOCLN_ACCDN</td>\n",
       "      <td>15009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>CD_COND_METEO</td>\n",
       "      <td>11922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>CD_ECLRM</td>\n",
       "      <td>11403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>CD_ETAT_SURFC</td>\n",
       "      <td>11273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>CD_GENRE_ACCDN</td>\n",
       "      <td>9045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>CD_ENVRN_ACCDN</td>\n",
       "      <td>5957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>CD_CATEG_ROUTE</td>\n",
       "      <td>5115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>LOC_Y</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>LOC_X</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Name Missing Values\n",
       "8   CD_CONFG_ROUTE          18738\n",
       "7   CD_LOCLN_ACCDN          15009\n",
       "9    CD_COND_METEO          11922\n",
       "4         CD_ECLRM          11403\n",
       "3    CD_ETAT_SURFC          11273\n",
       "2   CD_GENRE_ACCDN           9045\n",
       "5   CD_ENVRN_ACCDN           5957\n",
       "6   CD_CATEG_ROUTE           5115\n",
       "35           LOC_Y             11\n",
       "34           LOC_X             11"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# columns we are going to delete\n",
    "null_col = df.loc[:, df.isnull().sum(axis=0) < 5e4].columns # del more than 50,000 missing values\n",
    "null_num = df.loc[:, null_col].isnull().sum(axis=0)\n",
    "null_count = pd.DataFrame([null_col, null_num]).T\n",
    "null_count.columns = ['Name', 'Missing Values']\n",
    "null_count.sort_values(by='Missing Values', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keeping only rows with less than 20% of missing values\n",
    "df = df.loc[:, df.isnull().sum(axis=0) < 5e4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We now have 171,271 rows and 40 columns.\n"
     ]
    }
   ],
   "source": [
    "# new shape\n",
    "rows, columns = df.shape\n",
    "print(f'We now have {rows:,} rows and {columns} columns.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 1.29% missing values.\n"
     ]
    }
   ],
   "source": [
    "# new number of missing values \n",
    "missing_values = df.isnull().sum().sum()/df.size*100\n",
    "print('We have {}% missing values.'.format(np.round(missing_values, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our dataframe is 112 MB.\n"
     ]
    }
   ],
   "source": [
    "# size of the dataframe\n",
    "print(f'Our dataframe is {int(sys.getsizeof(df)/1e6)} MB.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "JR_SEMN_ACCDN      object\n",
       "DT_ACCDN           object\n",
       "CD_GENRE_ACCDN    float64\n",
       "CD_ETAT_SURFC     float64\n",
       "CD_ECLRM          float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# getting dtypes\n",
    "column_types = df.dtypes\n",
    "column_types.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping rows missing our target\n",
    "df.dropna(subset=['GRAVITE'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['NB_MORTS', 'NB_BLESSES_GRAVES', 'NB_BLESS_LEGERS', 'AN',\n",
       "       'NB_VICTIMES_TOTAL', 'NB_DECES_PIETON', 'NB_BLESSES_PIETON',\n",
       "       'NB_VICTIMES_PIETON', 'NB_DECES_MOTO', 'NB_BLESSES_MOTO',\n",
       "       'NB_VICTIMES_MOTO', 'NB_DECES_VELO', 'NB_BLESSES_VELO',\n",
       "       'NB_VICTIMES_VELO', 'LOC_COTE_P'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# getting columns by datatype\n",
    "integers = df.columns[column_types == 'int64']\n",
    "integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['CD_GENRE_ACCDN', 'CD_ETAT_SURFC', 'CD_ECLRM', 'CD_ENVRN_ACCDN',\n",
       "       'CD_CATEG_ROUTE', 'CD_LOCLN_ACCDN', 'CD_CONFG_ROUTE', 'CD_COND_METEO',\n",
       "       'NB_VEH_IMPLIQUES_ACCDN', 'nb_automobile_camion_leger',\n",
       "       'nb_camionLourd_tractRoutier', 'nb_outil_equipement',\n",
       "       'nb_tous_autobus_minibus', 'nb_bicyclette', 'nb_cyclomoteur',\n",
       "       'nb_motocyclette', 'LOC_X', 'LOC_Y', 'LOC_LONG', 'LOC_LAT'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# getting columns by datatype\n",
    "floats = df.columns[column_types == 'float64']\n",
    "floats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['JR_SEMN_ACCDN', 'DT_ACCDN', 'HR_ACCDN', 'GRAVITE', 'LOC_COTE_Q'], dtype='object')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# getting columns by datatype\n",
    "objects = df.columns[column_types == 'object']\n",
    "objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to make dummies\n",
    "def make_dummies(col):\n",
    "    global df\n",
    "    dummies = pd.get_dummies(df[col], prefix_sep=': ', prefix=col)\n",
    "    df = pd.concat([df, dummies], sort=False, axis=1)\n",
    "    df.drop(col, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to see value counts\n",
    "def vc(col):\n",
    "    return df[col].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# jour semaine\n",
    "df['JR_SEMN_ACCDN'] = df['JR_SEMN_ACCDN'].str.replace('DI', 'Dimanche')\n",
    "df['JR_SEMN_ACCDN'] = df['JR_SEMN_ACCDN'].str.replace('LU', 'Lundi')\n",
    "df['JR_SEMN_ACCDN'] = df['JR_SEMN_ACCDN'].str.replace('MA', 'Mardi')\n",
    "df['JR_SEMN_ACCDN'] = df['JR_SEMN_ACCDN'].str.replace('ME', 'Mercredi')\n",
    "df['JR_SEMN_ACCDN'] = df['JR_SEMN_ACCDN'].str.replace('JE', 'Jeudi')\n",
    "df['JR_SEMN_ACCDN'] = df['JR_SEMN_ACCDN'].str.replace('VE', 'Vendredi')\n",
    "df['JR_SEMN_ACCDN'] = df['JR_SEMN_ACCDN'].str.replace('SA', 'Samedi')\n",
    "\n",
    "df['JR_SEMN_ACCDN'].value_counts()\n",
    "make_dummies('JR_SEMN_ACCDN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# month\n",
    "month_dict = {\n",
    "    '01':'Janvier',\n",
    "    '02':'Février',\n",
    "    '03':'Mars',\n",
    "    '04':'Avril',\n",
    "    '05':'Mai',\n",
    "    '06':'Juin',\n",
    "    '07':'Juillet',\n",
    "    '08':'Août',\n",
    "    '09':'Septembre',\n",
    "    '10':'Octobre',\n",
    "    '11':'Novembre',\n",
    "    '12':'Décembre'\n",
    "}\n",
    "df['DT_ACCDN'] = df['DT_ACCDN'].str.split('/').str.get(1)\n",
    "df['DT_ACCDN'] = df['DT_ACCDN'].astype(str).replace(month_dict)\n",
    "make_dummies('DT_ACCDN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# genre d'accident\n",
    "genre_dict = {\n",
    "    '31':'Collision avec véhicule routier',\n",
    "    '32':'Collision avec piéton',\n",
    "    '33':'Collision avec cycliste',\n",
    "    '34':'Collision avec train',\n",
    "    '35':'Collision avec chevreuil (cerf de Virginie)',\n",
    "    '36':'Collision avec orignal/ours/caribou',\n",
    "    '37':'Collision avec autre animal',\n",
    "    '38':'Collision avec obstacle temporaire',\n",
    "    '39':'Collision avec objet projeté/détaché',\n",
    "    '40':'Objet fixe: lampadaire',\n",
    "    '41':'Objet fixe: support/feu de signalisation',\n",
    "    '42':'Objet fixe: poteau (service public)',\n",
    "    '43':'Objet fixe: arbre',\n",
    "    '44':'Objet fixe: section de glissière de sécurité',\n",
    "    '45':'Objet fixe: atténuateur d’impact',\n",
    "    '46':'Objet fixe: extrémité de glissière de sécurité',\n",
    "    '47':'Objet fixe: pilier (pont/tunnel)',\n",
    "    '48':'Objet fixe: amoncellement de neige',\n",
    "    '49':'Objet fixe: bâtiment/édifice/mur',\n",
    "    '50':'Objet fixe: bordure/trottoir',\n",
    "    '51':'Objet fixe: borne-fontaine',\n",
    "    '52':'Objet fixe: clôture/barrière',\n",
    "    '53':'Objet fixe: fossé',\n",
    "    '54':'Objet fixe: paroi rocheuse',\n",
    "    '55':'Objet fixe: ponceau',\n",
    "    '59':'Objet fixe: autre objet fixe',\n",
    "    '71':'Sans collision: capotage',\n",
    "    '72':'Sans collision: renversement',\n",
    "    '73':'Sans collision: submersion/cours d’eau',\n",
    "    '74':'Sans collision: feu/explosion',\n",
    "    '75':'Sans collision: quitte la chaussée',\n",
    "    '99':'Sans collision: autre'    \n",
    "}\n",
    "df['CD_GENRE_ACCDN'] = df['CD_GENRE_ACCDN'].astype(str).replace(genre_dict)\n",
    "make_dummies('CD_GENRE_ACCDN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# etat de la surface\n",
    "surface_dict = {\n",
    "    '11.0':'Sèche',\n",
    "    '12.0':'Mouillée',\n",
    "    '13.0':'Accumulation d\\'eau',\n",
    "    '14.0':'Sable, gravier',\n",
    "    '15.0':'Gadoue',\n",
    "    '16.0':'Enneigée',\n",
    "    '17.0':'Neige durcie',\n",
    "    '18.0':'Glacée',\n",
    "    '19.0':'Boueuse',\n",
    "    '20.0':'Huileuse',\n",
    "    '90.0':'Autre'\n",
    "}\n",
    "df['CD_ETAT_SURFC'] = df['CD_ETAT_SURFC'].astype(str).replace(surface_dict)\n",
    "make_dummies('CD_ETAT_SURFC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eclairement\n",
    "ecl_dict = {\n",
    "    '1':'Jour et clarté',\n",
    "    '2':'Jour et demi-obscurité',\n",
    "    '3':'Nuit et chemin éclairé',\n",
    "    '4':'Nuit et chemin non éclairé'\n",
    "}\n",
    "make_dummies('CD_ECLRM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# environment\n",
    "env_dict = {\n",
    "    '1':'Scolaire',\n",
    "    '2':'Résidentiel',\n",
    "    '3':'Commercial',\n",
    "    '4':'Industriel',\n",
    "    '5':'Rural',\n",
    "    '6':'Forestier',\n",
    "    '7':'Récréatif',\n",
    "    '9':'Autre'\n",
    "}\n",
    "df['CD_ENVRN_ACCDN'] = df['CD_ENVRN_ACCDN'].astype(str).replace(env_dict)\n",
    "make_dummies('CD_ENVRN_ACCDN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type route\n",
    "categ_dict = {\n",
    "    '11':'Chemin public: bretelle/collecteur d’autoroute/voie de service',\n",
    "    '12':'Chemin public: route numérotée',\n",
    "    '13':'Chemin public: artère principale',\n",
    "    '14':'Chemin public: rue résidentielle',\n",
    "    '15':'Chemin public: chemin/rang',\n",
    "    '16':'Chemin public: ruelle',\n",
    "    '19':'Chemin public: autre',\n",
    "    '21':'Hors chemin public: terrain de stationnement',\n",
    "    '22':'Hors chemin public: terrain privé',\n",
    "    '23':'Hors chemin public: chemin privé',\n",
    "    '24':'Hors chemin public: chemin forestier',\n",
    "    '25':'Hors chemin public: sentier balisé',\n",
    "    '29':'Hors chemin public: autre',\n",
    "}\n",
    "df['CD_CATEG_ROUTE'] = df['CD_CATEG_ROUTE'].astype(str).replace(categ_dict)\n",
    "make_dummies('CD_CATEG_ROUTE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# localisation\n",
    "loc_dict = {\n",
    "    '31':'Carrefour giratoire/rond-point',\n",
    "    '32':'En intersection (moins de 5 mètres)',\n",
    "    '33':'Près d’une intersection/carrefour giratoire',\n",
    "    '34':'Entre intersections (100 mètres et +)',\n",
    "    '35':'Passage à niveau',\n",
    "    '36':'Pont (au-dessus d’un cours d’eau)',\n",
    "    '37':'Autre pont (viaduc)',\n",
    "    '38':'Tunnel',\n",
    "    '39':'Sous un pont ou un viaduc',\n",
    "    '40':'Centre commercial',\n",
    "    '99':'Autres'\n",
    "}\n",
    "df['CD_LOCLN_ACCDN'] = df['CD_LOCLN_ACCDN'].astype(str).replace(loc_dict)\n",
    "make_dummies('CD_LOCLN_ACCDN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configuration\n",
    "config_dict = {\n",
    "    '1':'Sens unique',\n",
    "    '2':'Deux sens, une voie par direction',\n",
    "    '3':'Deux sens, plus d’une voie par direction',\n",
    "    '4':'Séparée par aménagement franchissable',\n",
    "    '5':'Séparée par aménagement infranchissable',\n",
    "    '6':'Autre (ex.: balises, voie de virage à gauche dans les deux sens)'\n",
    "}\n",
    "df['CD_CONFG_ROUTE'] = df['CD_CONFG_ROUTE'].astype(str).replace(config_dict)\n",
    "make_dummies('CD_CONFG_ROUTE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# meteo\n",
    "meteo_dict = {\n",
    "    '11':'Clair',\n",
    "    '12':'Couvert',\n",
    "    '13':'Brume',\n",
    "    '14':'Pluie',\n",
    "    '15':'Pluie forte',\n",
    "    '16':'Vent fort',\n",
    "    '17':'Neige',\n",
    "    '18':'Poudrerie avec vent',\n",
    "    '19':'Verglas',\n",
    "    '10':'Autre'\n",
    "}\n",
    "df['CD_COND_METEO'] = df['CD_COND_METEO'].astype(str).replace(meteo_dict)\n",
    "make_dummies('CD_COND_METEO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# heure\n",
    "heure_dict = {\n",
    "    'Non précisé':'Inconnu',         \n",
    "    '16:00:00-16:59:00':'16h__',\n",
    "    '15:00:00-15:59:00':'15h__',\n",
    "    '17:00:00-17:59:00':'17h__',\n",
    "    '14:00:00-14:59:00':'14h__',\n",
    "    '12:00:00-12:59:00':'12h__',\n",
    "    '13:00:00-13:59:00':'13h__',\n",
    "    '08:00:00-08:59:00':'08h__',\n",
    "    '18:00:00-18:59:00':'18h__',\n",
    "    '11:00:00-11:59:00':'11h__',\n",
    "    '10:00:00-10:59:00':'10h__',\n",
    "    '09:00:00-09:59:00':'09h__',\n",
    "    '19:00:00-19:59:00':'19h__',\n",
    "    '07:00:00-07:59:00':'07h__',\n",
    "    '20:00:00-20:59:00':'20h__',\n",
    "    '21:00:00-21:59:00':'21h__',\n",
    "    '22:00:00-22:59:00':'22h__',\n",
    "    '23:00:00-23:59:00':'23h__',\n",
    "    '00:00:00-00:59:00':'00h__',\n",
    "    '06:00:00-06:59:00':'06h__',\n",
    "    '03:00:00-03:59:00':'03h__',\n",
    "    '01:00:00-01:59:00':'01h__',\n",
    "    '02:00:00-02:59:00':'02h__',\n",
    "    '04:00:00-04:59:00':'04h__',\n",
    "    '05:00:00-05:59:00':'05h__'\n",
    "}\n",
    "df['HR_ACCDN'] = df['HR_ACCDN'].astype(str).replace(heure_dict)\n",
    "make_dummies('HR_ACCDN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gravite\n",
    "df['GRAVITE'] = df['GRAVITE'].str.replace('inférieurs au seuil de rapportage', '(inférieurs)')\n",
    "make_dummies('GRAVITE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['NB_VEH_IMPLIQUES_ACCDN', 'NB_MORTS', 'NB_BLESSES_GRAVES',\n",
       "       'NB_BLESS_LEGERS', 'AN', 'NB_VICTIMES_TOTAL',\n",
       "       'nb_automobile_camion_leger', 'nb_camionLourd_tractRoutier',\n",
       "       'nb_outil_equipement', 'nb_tous_autobus_minibus', 'nb_bicyclette',\n",
       "       'nb_cyclomoteur', 'nb_motocyclette', 'NB_DECES_PIETON',\n",
       "       'NB_BLESSES_PIETON', 'NB_VICTIMES_PIETON', 'NB_DECES_MOTO',\n",
       "       'NB_BLESSES_MOTO', 'NB_VICTIMES_MOTO', 'NB_DECES_VELO',\n",
       "       'NB_BLESSES_VELO', 'NB_VICTIMES_VELO', 'LOC_X', 'LOC_Y', 'LOC_COTE_Q',\n",
       "       'LOC_COTE_P', 'LOC_LONG', 'LOC_LAT'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# final columns\n",
    "df.columns[:28]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 171,271 rows and 179 columns.\n"
     ]
    }
   ],
   "source": [
    "# final shape\n",
    "rows, columns = df.shape\n",
    "print(f'We have {rows:,} rows and {columns} columns.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exports processed data to csv \n",
    "df.to_csv('a_dummies.csv', header=True, index=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
